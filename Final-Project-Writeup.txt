Speaker Recognition for Regional Accent Placement
Daniel Arthur and Saul Backer
LING 550 Final Project
December 12th, 2016
Introduction
The object of our project was to build a speaker recognition software application that could accurately identify a speaker’s region by their regional accent. Speech recognition software tends to be unreliable when an accent varies from the data the system was trained on, and “performance deteriorates further” when the subject is a non-native speaker (Kat and Fung). If a speech recognition system could identify the accent of a user, it might be better equipped to recognize and accurately parse speech. Our system is meant to help deal with the issue of accent placement by identifying regional accents in American English, which could be the first step in dealing with identifying the accents of non-native speakers. 

2.  Related Research
The extraction and analysis of formant frequency values and acoustic information seems to be the most commonly utilized method of trying to identify speakers’ accents. Vowels are the most dynamic parts of speech in regards to phonetic variation, and because vowels have the highest periodic acoustic energy their formants are the easiest to identify and the most subject to change. Kat and Fung posit that the relative importance of different formants is not always constant, and that some formants are more useful for identifying specific accents. They take into account not only formant values but also “energy… and fundamental frequency” as “discriminative features for identifying a Cantonese (and possibly other Asian) accents”, while also writing F2 and F3 are the most indicative for European accents. Stantic and Jo similarly analyze the relationships between formants’ frequency values and conclude that formants tend to cluster around a similar range of frequencies for a given accent, which would help in accent identification. 
2.1 Similar Projects
While there is quite a lot of research on the subject of accent identification for both native and non-native speakers of a language, we have not found very much evidence of a software application similar to ours. The number of confounding variables related to this task makes it very difficult to accurately predict a region. Perhaps our fairly low success rate and the difficulties we encountered in improving the accuracy speak to the lack of similar projects. 

3. Methodology
We attempted to create an application that would differentiate and label speakers by region based on the values of their formants. Our data was obtained from the TIMIT acoustic-phonetic continuous speech corpus, and was comprised of audio and text files from both male and female speakers from seven regions within the United States. The TIMIT data was divided into 80% training data and 20% test data. We wanted to find the average formant values for F1 and F2 for each of the vowels for a given speaker. Then in the test data, we could compare the averages from one vowel for a speaker to all of the average formant values for that vowel using a nearest neighbors classifier. 
3.1 File Alignment and Extraction 
The alignment and formant extraction of the TIMIT files were done using the Forced Alignment and Vowel Extraction (FAVE) software suite. In order to pass the files into FAVE align, which creates text grids for FAVE extract, we had to modify all of TIMIT files to add the region and the length of the audio clip so that FAVE align could work with them. We ran into a number of issues while working with the TIMIT corpus, because it is significantly older than FAVE. There were a number of typos within TIMIT, which would ensnare our reformatting algorithm. When we got it working with the TIMIT data, Fave Align gave text grid files as output, which we then passed to FAVE extract to find formant values for each of the vowels for each speaker in each region. While our research indicates that F3 is often the most useful for distinguishing accents, FAVE extract only allows us to find F1 and F2 values.

3.2 Formant Averages and KNN Classifier
Using the data we obtained from using FAVE align and extract, we found the average formant values for F1 and F2 for every vowel. We needed a way to compare these values to all of the other values for the same vowel, so we used a nearest neighbors classifier, specifically the scikit.learn KNN. Every vowel for a given speaker in the test data was compared to all other instances of the same vowel in the training data using the KNN classifier, and then that vowel was labeled with a predicted region based on its euclidean distance from its nearest neighbors. The speaker of those vowels was given whatever label the KNN classifier predicted the most. We found that our program had the highest accuracy with a K value of 2 or 5. 

4. Results, Shortcomings and Future Work
The biggest problem with our experiment was its accuracy. For a number of regions, our program was no where close to predicting the correct label for a given speaker. As illustrated in the table below, we did have a few regions which had better performance. 


The prediction that a test speaker was from a southern region was vastly overrepresented, which is problematic to say the least. We tried a number of approaches to improve the accuracy of our system. We tried running the program with the data divided by the sex of the speaker, which did nothing. We also changed the K value in the KNN classifier, which had only a very small effect. We compared a single vowel from the test data to every vowel in the training data, rather than just comparing it to other instances of that vowel, but that didn’t improve the accuracy either. Adding a comparison of F3 values probably would have helped, but unfortunately FAVE extract does not allow us to extract F3 values.  However, it may be the case that formant analysis alone is not a sufficient way of addressing this issue.  Perhaps, a system that would really achieve favourable results would be one that takes into account phonological and prosodic variation. Working with the TIMIT corpus also provided difficulties, as there were numerous errors within the corpus that hindered our ability to smoothly integrate it into FAVE. Also, TIMIT did not have the same number of files for every region or every sex, so we had to edit our data evening out the number of speakers by eliminating some. Clearly, in the future we would like to make our predictions to be accurate. If we could accomplish this, then ideally this project would be expanded to include identification of accents  outside of the US. Eventually, we would hope this sort of software could be used for non-native speakers’ accent identification in order to help with foreign accent speech recognition. 

Works Cited: 
- "Forced Alignment & Vowel Extraction (FAVE)." Welcome to FAVE - an Online Suite for Automatic Vowel Analysis. N.p., n.d. Web. 04 Dec. 2016.
- JoFrhwld. "JoFrhwld/FAVE." GitHub. N.p., 06 Oct. 2015. Web. 04 Dec. 2016. <https://github.com/JoFrhwld/FAVE>.
 - Kat, Liu Wai, and P. Fung. "Fast Accent Identification and Accented Speech Recognition." 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258) (1999): n. pag. University of Science and Technology Clear Water Bay, Hong Kong. Web.
- Stantic, Dejan, and Jun Jo. "Accent Identification by Clustering and Scoring Formants." International Journal of Computer, Electrical, Automation, Control and Information Engineering, n.d. Web. <http://waset.org/publications/5405/accent-identification-by-clustering-and-scoring-formants>.
- "TIMIT Acoustic-Phonetic Continuous Speech Corpus." Linguistic Data Consortium. N.p., n.d. Web. 04 Dec. 2016.